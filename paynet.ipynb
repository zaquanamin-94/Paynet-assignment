{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kagglehub[pandas-datasets]\n",
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, explode, from_json, from_utc_timestamp, regexp_replace, split, trim, concat, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, DateType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CCsample\").getOrCreate()\n",
    "\n",
    "df_raw = spark.read.option(\"inferSchema\",\"true\").json(\"cc_sample/cc_sample_transaction.json\")\n",
    "\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON schema of `personal_detail`\n",
    "personal_detail_schema = StructType([\n",
    "    StructField(\"person_name\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"lat\", StringType()),\n",
    "    StructField(\"long\", StringType()),\n",
    "    StructField(\"city_pop\", IntegerType()),\n",
    "    StructField(\"job\", StringType()),\n",
    "    StructField(\"dob\", DateType())\n",
    "])\n",
    "\n",
    "# Schema for `address` (nested inside `personal_detail`)\n",
    "address_schema = StructType([\n",
    "    StructField(\"street\", StringType()),\n",
    "    StructField(\"city\", StringType()),\n",
    "    StructField(\"state\", StringType()),\n",
    "    StructField(\"zip\", StringType())\n",
    "])\n",
    "\n",
    "# Convert `personal_detail` from STRING to STRUCT\n",
    "df_flat_pd = df_raw.withColumn(\"personal_detail\", from_json(col(\"personal_detail\"), personal_detail_schema))\n",
    "\n",
    "# Convert `address` (inside `personal_detail`) from STRING to STRUCT\n",
    "df_flat_address = df_flat_pd.withColumn(\"address\", from_json(col(\"personal_detail.address\"), address_schema))\n",
    "\n",
    "df_clean_name = df_flat_address.withColumn(\"clean_name\", regexp_replace(\"personal_detail.person_name\", \"[^a-zA-Z]\", \" \"))\\\n",
    "                            .withColumn(\"clean_name\", trim(regexp_replace(\"clean_name\", r\"\\s+\", \" \"))) \\\n",
    "                            .withColumn(\"first\", split(\"clean_name\", \" \")[0]) \\\n",
    "                            .withColumn(\"last\", split(\"clean_name\", \" \")[1])\n",
    "\n",
    "df_clean_epoch = df_clean_name.withColumn(\n",
    "                        \"clean_eff_time\",\n",
    "                        F.when(F.length(F.col(\"merch_eff_time\")) == 10,  # Epoch in seconds\n",
    "                            from_utc_timestamp(F.from_unixtime(F.col(\"merch_eff_time\")),\"Asia/Singapore\"))\n",
    "                        .when((F.length(F.col(\"merch_last_update_time\")) == 11),  # Epoch in milliseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(concat(F.col(\"merch_last_update_time\"),F.lit(\"00\")) / 1000),\"Asia/Singapore\"))\n",
    "                        .when((F.length(F.col(\"merch_last_update_time\")) == 12),  # Epoch in milliseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(concat(F.col(\"merch_last_update_time\"),F.lit(\"0\")) / 1000),\"Asia/Singapore\"))\n",
    "                        .when((F.length(F.col(\"merch_last_update_time\")) == 13),  # Epoch in milliseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(F.col(\"merch_last_update_time\") / 1000),\"Asia/Singapore\"))\n",
    "                        .when((F.length(F.col(\"merch_eff_time\")) == 13),  # Epoch in milliseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(F.col(\"merch_eff_time\") / 1000),\"Asia/Singapore\"))\n",
    "                        .when(F.length(F.col(\"merch_eff_time\")) == 16,  # Epoch in microseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(F.col(\"merch_eff_time\") / 1_000_000),\"Asia/Singapore\"))\n",
    "                        .otherwise(None)  # Handle invalid values\n",
    "                    ) \\\n",
    "                   .withColumn(\n",
    "                        \"clean_merch_last_update_time\",\n",
    "                        F.when((F.length(F.col(\"merch_last_update_time\")) == 10),  # Epoch in seconds\n",
    "                            from_utc_timestamp(F.from_unixtime(F.col(\"merch_last_update_time\")),\"Asia/Singapore\"))\n",
    "                        .when((F.length(F.col(\"merch_last_update_time\")) == 11),  # Epoch in milliseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(concat(F.col(\"merch_last_update_time\"),F.lit(\"00\")) / 1000),\"Asia/Singapore\"))\n",
    "                        .when((F.length(F.col(\"merch_last_update_time\")) == 12),  # Epoch in milliseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(concat(F.col(\"merch_last_update_time\"),F.lit(\"0\")) / 1000),\"Asia/Singapore\"))\n",
    "                        .when((F.length(F.col(\"merch_last_update_time\")) == 13),  # Epoch in milliseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(F.col(\"merch_last_update_time\") / 1000),\"Asia/Singapore\"))\n",
    "                        .when(F.length(F.col(\"merch_last_update_time\")) == 16,  # Epoch in microseconds\n",
    "                            from_utc_timestamp(F.from_unixtime(F.col(\"merch_last_update_time\") / 1_000_000),\"Asia/Singapore\"))\n",
    "                        .otherwise(None)  # Handle invalid values\n",
    "                   )\n",
    "\n",
    "\n",
    "df_clean_epoch.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select flattened columns\n",
    "df_flat = df_clean_epoch.select(\n",
    "    col(\"Unnamed: 0\"),\n",
    "    from_utc_timestamp(col(\"trans_date_trans_time\"),\"Asia/Singapore\").alias(\"trans_date_trans_time\"),\n",
    "    col(\"cc_num\"),\n",
    "    col(\"merchant\"),\n",
    "    col(\"category\"),\n",
    "    col(\"amt\").cast(DoubleType()),\n",
    "    col(\"first\"),\n",
    "    col(\"last\"),\n",
    "    col(\"personal_detail.gender\").alias(\"gender\"),\n",
    "    col(\"address.street\").alias(\"street\"),\n",
    "    col(\"address.city\").alias(\"city\"),\n",
    "    col(\"address.state\").alias(\"state\"),\n",
    "    col(\"address.zip\").alias(\"zip\"),\n",
    "    col(\"personal_detail.lat\").alias(\"lat\"),\n",
    "    col(\"personal_detail.long\").alias(\"long\"),\n",
    "    col(\"personal_detail.city_pop\").alias(\"city_pop\"),\n",
    "    col(\"personal_detail.job\").alias(\"job\"),\n",
    "    col(\"personal_detail.dob\").alias(\"dob\"),\n",
    "    col(\"trans_num\"),\n",
    "    col(\"merch_lat\"),\n",
    "    col(\"merch_long\"),\n",
    "    col(\"is_fraud\"),\n",
    "    col(\"merch_zipcode\"),\n",
    "    col(\"clean_merch_last_update_time\").alias(\"merch_last_update_time\"),\n",
    "    col(\"clean_eff_time\").alias(\"merch_eff_time\"),\n",
    "    col(\"cc_bic\")\n",
    ")\n",
    "\n",
    "# df_flat.printSchema()\n",
    "# Show result\n",
    "df_flat.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paynet-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
